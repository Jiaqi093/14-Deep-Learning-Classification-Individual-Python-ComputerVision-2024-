{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YK-ajsgkvxh",
        "outputId": "caca47ba-4cd3-4208-e085-0aa6b5ec6c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version:  2.0.0+cu118\n",
            "torchvision version:  0.15.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(\"PyTorch version: \", torch.__version__)\n",
        "print(\"torchvision version: \", torchvision.__version__)\n",
        "import torch\n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JIHI-VTkza1",
        "outputId": "709ad9e3-434e-4ff9-95bf-c68fcb709f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to('cuda')\n",
        "\n",
        "print(f\"Device: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Azf6l0lyatCi"
      },
      "outputs": [],
      "source": [
        "#@title Define some hyper-parameters\n",
        "\n",
        "data_path = 'data/fashion' #@param {type: 'string'}\n",
        "batch_size = 1024     #@param {type: 'number'}\n",
        "\n",
        "log_dir = \"./runs/lab_2\" #@param {type: 'string'}\n",
        "device = 'cpu'  #@param ['cpu', 'cuda']\n",
        "\n",
        "learning_rate = 0.001 #@param {type: 'number'}\n",
        "epochs = 5 #@param {type: 'number'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9muozvBGNWsK"
      },
      "source": [
        "# Create training, validation and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bf1UTSWiNUZ9"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data\n",
        "!mkdir -p data/fashion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PBl66omHBksd"
      },
      "outputs": [],
      "source": [
        "from data import mnist_reader\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, y_train = mnist_reader.load_mnist(data_path, kind='train')\n",
        "test_x, test_y = mnist_reader.load_mnist(data_path, kind='t10k')\n",
        "train_x, val_x, train_y, val_y = train_test_split(X_train, y_train, test_size=0.3, random_state=1, shuffle=True, stratify=None) # training validation set split\n",
        "        \n",
        "# test_x = torch.from_numpy(test_x)\n",
        "# test_y = torch.from_numpy(test_y)\n",
        "# train_x = torch.from_numpy(train_x)\n",
        "# train_y = torch.from_numpy(train_y)\n",
        "# val_x = torch.from_numpy(val_x)\n",
        "# val_y = torch.from_numpy(val_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RyeatZY9OfA"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkbDhmJu9Pqe",
        "outputId": "7731cde5-fedc-4be1-a90a-0f8f6a3db585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyModel(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn   \n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyModel(nn.Module):  # inherit from nn.Module class\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2) # stride means how many pixels need to move\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1) # outchannel in conv1 is the inchannel in conv2\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=64*7*7, out_features=1024) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=1024, out_features=10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape [batch_size, channel, height, width]  [B, 3, 32, 32]\n",
        "        x = self.conv1(x) \n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x) #[1024, 64, 7, 7]\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel() # instantiate a model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AS8U4QmO6vfK"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn   \n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyModel2(nn.Module):  \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=128*7*7, out_features=1024)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(in_features=512, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) \n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x) \n",
        "        x = x.view(-1, 128 * 7 * 7)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel2() # instantiate a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gLvYq7Qc-bxo"
      },
      "outputs": [],
      "source": [
        "#@title Train Loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, device, epoch): \n",
        "\n",
        "    print(\"training data...\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    # Get a batch of training data from the DataLoader\n",
        "    for batch, data in enumerate(dataloader):\n",
        "        # Every data instance is an image + label pair\n",
        "        img, label = data\n",
        "\n",
        "        # Transfer data to target device\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Zero your gradients for every batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute prediction for this batch\n",
        "        logit = model(img)\n",
        "\n",
        "        # compute the loss and its gradients\n",
        "        loss = loss_fn(logit, label)\n",
        "\n",
        "        # Calculate the index of maximum logit as the predicted label\n",
        "        prob = F.softmax(logit, dim=1)\n",
        "        pred = prob.argmax(dim=1)\n",
        "        # record correct predictions\n",
        "        correct += (pred == label).type(torch.float).sum().item()\n",
        "        total += label.size(0)\n",
        "\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters according to gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()     # ! Don't forget to use .item() to retrieve loss value  \n",
        "        total_loss += loss.item()\n",
        "        # report every 100 iterations\n",
        "        if batch % 100 == 99:\n",
        "            print(' epoch {} loss: {:.4f}'.format(epoch+1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    train_loss = total_loss / (batch+1)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return train_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Mu705ULV-hE6"
      },
      "outputs": [],
      "source": [
        "#@title Evaluation Loop\n",
        "def evaluate_loop(dataloader, model, loss_fn, device): \n",
        "\n",
        "    print(\"evaluating data...\")\n",
        "    # Get number of batches\n",
        "    #num_batches = len(dataloader)\n",
        "\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    \n",
        "    # Context-manager that disabled gradient calculation.\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            # Every data instance is an image + label pair\n",
        "            img, label = data\n",
        "            # Transfer data to target device\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            # Compute prediction for this batch\n",
        "            logit = model(img)\n",
        "\n",
        "            # compute the loss\n",
        "            test_loss += loss_fn(logit, label).item()    # ! Don't forget .item() again!!!\n",
        "\n",
        "            # Calculate the index of maximum logit as the predicted label\n",
        "            prob = F.softmax(logit, dim=1)\n",
        "            pred = prob.argmax(dim=1)\n",
        "            # record correct predictions\n",
        "            correct += (pred == label).type(torch.float).sum().item()\n",
        "            total += label.size(0)\n",
        "    # Gather data and report\n",
        "    test_loss /= 64\n",
        "    accuracy = correct / total\n",
        "    print(\"Test Error: \\n   Accuracy: {:.2f}, Avg loss: {:.4f} \\n\".format(100*accuracy, test_loss))\n",
        "    \n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bKOlaLvnKws"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iYFmZJRXnJlo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from data import mnist_reader\n",
        "\n",
        "labels_map = {\n",
        "    0: \"T-shirt/top\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle boot\",\n",
        "}\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image, label, transform):\n",
        "        super().__init__()\n",
        "\n",
        "        self.image = image\n",
        "        self.label = label\n",
        "\n",
        "        self.image = self.image.reshape(-1, 28, 28)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image[idx]\n",
        "        label = self.label[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(Image.fromarray(image))\n",
        "        label = torch.tensor(label).long()\n",
        "        return image, label "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRIdGytz_rdk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU-KJirH_sy6",
        "outputId": "2f958db8-1578-4fa0-8048-740f732f79fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size:  1024\n",
            "Learning rate:  0.001\n",
            "Total epochs:  5\n",
            "Set up dataset ...\n",
            "Train dataset contains: 42000 samples\n",
            "Validation dataset contains: 18000 samples\n",
            "Test dataset contains: 10000 samples\n",
            "current epoch is:  1\n",
            "training data...\n",
            "evaluating data...\n",
            "Test Error: \n",
            "   Accuracy: 34.59, Avg loss: 0.4997 \n",
            "\n",
            "current epoch is:  2\n",
            "training data...\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# log some hyper-parameters\n",
        "print(\"Batch size: \", batch_size)\n",
        "print(\"Learning rate: \", learning_rate)\n",
        "print(\"Total epochs: \", epochs)\n",
        "# ******************* Dataset *******************\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5), # normalize the data to the range (-1, 1)\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    transforms.RandomHorizontalFlip(0.5), # the image will be flipped with 50% probability left and right\n",
        "    transforms.Pad(padding=4, fill=0, padding_mode='constant'),  # zero padded 4 pixels  \n",
        "    transforms.RandomCrop(size=28), #randomly crop 28x28 as input\n",
        "    ])\n",
        "\n",
        "# We should not do any data augmentation for evaluation.\n",
        "evaluate_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "    ])\n",
        "\n",
        "train_dataset = CustomDataset(train_x, train_y, transform=train_transform)\n",
        "valid_dataset = CustomDataset(val_x, val_y, transform=evaluate_transform)\n",
        "test_dataset = CustomDataset(test_x, test_y, transform=evaluate_transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    )\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    )\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    )\n",
        "print(\"Set up dataset ...\")\n",
        "print(\"Train dataset contains: %d samples\" % len(train_dataset))\n",
        "print(\"Validation dataset contains: %d samples\" % len(valid_dataset))\n",
        "print(\"Test dataset contains: %d samples\" % len(test_dataset))\n",
        "\n",
        "# ******************* TensorBoard *******************\n",
        "writer = SummaryWriter('runs/lab_2')\n",
        "\n",
        "\n",
        "# ******************************************************************************** Model ******************************************************************************************************\n",
        "model = MyModel2()\n",
        "# ******************************************************************************** Model ******************************************************************************************************\n",
        "\n",
        "# save model graph to tensorboard\n",
        "imgs, labels = next(iter(train_loader)) # Get an example data batch\n",
        "writer.add_graph(model, imgs)\n",
        "\n",
        "# move model to target device\n",
        "model.to(device)\n",
        "\n",
        "# ******************* Loss & Optimizer *******************\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ******************* Optimization *******************\n",
        "best_accuracy = 0.\n",
        "for epoch in range(1, epochs+1):\n",
        "    print(\"current epoch is: \" , epoch)\n",
        "    # train loop\n",
        "    # set the module in training mode.\n",
        "    model.train()\n",
        "    train_loss, train_accuracy = train_loop(train_loader, model, loss_fn, optimizer, device, epoch)\n",
        "\n",
        "    # save to tensorboard\n",
        "    writer.add_scalar('train_loss vs epochs', train_loss, epoch)\n",
        "    writer.add_scalar('train_accuracy vs epochs', train_loss, epoch)\n",
        "    \n",
        "    # save model weights\n",
        "    save_path = 'ckpt_{:04d}.pth'.format(epoch+1)\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    # validation loop\n",
        "    # set the module in evaluation mode.\n",
        "    model.eval()\n",
        "    valid_loss, valid_accuracy = evaluate_loop(valid_loader, model, loss_fn, device)\n",
        "    # save to tensorboard\n",
        "    writer.add_scalar('valid_loss vs epochs', valid_loss, epoch)\n",
        "    writer.add_scalar('valid_accuracy vs epochs', valid_accuracy, epoch)\n",
        "    if valid_accuracy > best_accuracy:    # save the model with best validation accuracy\n",
        "        save_path = 'ckpt_best.pth'\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        best_accuracy = valid_accuracy\n",
        "\n",
        "writer.close()\n",
        "print(\"Finished Training.\")\n",
        "\n",
        "# load the parameters to the same device\n",
        "state_dict = torch.load('ckpt_best.pth', map_location=device)\n",
        "model.load_state_dict(state_dict)   # load parameters to model instance\n",
        "model.eval()\n",
        "test_loss, test_accuracy = evaluate_loop(test_loader, model, loss_fn, device)\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir ./runs/lab_2 --port 6006"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
